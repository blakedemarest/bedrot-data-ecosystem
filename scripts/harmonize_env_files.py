#!/usr/bin/env python3
"""
Harmonize environment files across the BEDROT ecosystem.
Standardizes paths, removes duplicates, and ensures consistency.
"""

import os
from pathlib import Path
import re
from datetime import datetime

# Standard root path for the ecosystem
# Windows format for .env files
ECOSYSTEM_ROOT_WIN = r"C:\Users\Earth\BEDROT PRODUCTIONS\bedrot-data-ecosystem"
# WSL format for file access
ECOSYSTEM_ROOT = "/mnt/c/Users/Earth/BEDROT PRODUCTIONS/bedrot-data-ecosystem"

def backup_file(file_path):
    """Create a backup of the file before modifying."""
    backup_path = f"{file_path}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    with open(file_path, 'r') as f:
        content = f.read()
    with open(backup_path, 'w') as f:
        f.write(content)
    print(f"‚úì Backed up {file_path} to {backup_path}")
    return backup_path

def standardize_env_file(env_path, component_name):
    """Standardize an environment file for a specific component."""
    print(f"\nüîß Processing {env_path}...")
    
    if not os.path.exists(env_path):
        print(f"  ‚ö†Ô∏è  File not found: {env_path}")
        return
    
    # Backup first
    backup_file(env_path)
    
    # Read current content
    with open(env_path, 'r') as f:
        lines = f.readlines()
    
    # Define standard variables for each component (using Windows paths)
    standard_vars = {
        'root': {
            'PROJECT_ROOT': ECOSYSTEM_ROOT_WIN,
            'ENVIRONMENT': 'development',
            'DATA_LAKE_PATH': f'{ECOSYSTEM_ROOT_WIN}\\data_lake',
            'DATA_WAREHOUSE_PATH': f'{ECOSYSTEM_ROOT_WIN}\\data-warehouse',
            'DASHBOARD_PATH': f'{ECOSYSTEM_ROOT_WIN}\\data_dashboard',
        },
        'data_lake': {
            'PROJECT_ROOT': f'{ECOSYSTEM_ROOT_WIN}\\data_lake',
            'LANDING_PATH': 'landing',
            'RAW_PATH': 'raw',
            'STAGING_PATH': 'staging',
            'CURATED_PATH': 'curated',
            'ARCHIVE_PATH': 'archive',
        },
        'data_warehouse': {
            'PROJECT_ROOT': f'{ECOSYSTEM_ROOT_WIN}\\data-warehouse',
            'DATABASE_PATH': 'bedrot_analytics.db',
            'CURATED_DATA_PATH': f'{ECOSYSTEM_ROOT_WIN}\\data_lake\\curated',
        },
        'dashboard': {
            'PROJECT_ROOT': f'{ECOSYSTEM_ROOT_WIN}\\data_dashboard',
            'CURATED_DATA_PATH': f'{ECOSYSTEM_ROOT_WIN}\\data_lake\\curated',
            'DATABASE_PATH': f'{ECOSYSTEM_ROOT_WIN}\\data-warehouse\\bedrot_analytics.db',
        }
    }
    
    # Process lines
    new_lines = []
    seen_vars = set()
    postgresql_section = False
    
    # Add header if missing
    if not any('BEDROT' in line for line in lines[:5]):
        new_lines.append(f"# BEDROT {component_name.upper()} Environment Configuration\n")
        new_lines.append(f"# Generated by harmonize_env_files.py on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        new_lines.append("\n")
    
    # Add standard variables first
    new_lines.append("# === Core Configuration ===\n")
    for var, value in standard_vars.get(component_name, {}).items():
        new_lines.append(f"{var}={value}\n")
        seen_vars.add(var)
    new_lines.append("\n")
    
    # Process existing lines
    for line in lines:
        # Skip PostgreSQL configuration (not used)
        if 'POSTGRES' in line or 'PGUSER' in line or 'PGPASSWORD' in line:
            postgresql_section = True
            continue
        
        # Skip empty lines in PostgreSQL section
        if postgresql_section and line.strip() == '':
            postgresql_section = False
            continue
            
        # Skip duplicate PROJECT_ROOT definitions
        if line.startswith('PROJECT_ROOT='):
            continue
            
        # Fix path inconsistencies
        if 'BEDROT DATA LAKE' in line:
            line = line.replace('BEDROT DATA LAKE', 'bedrot-data-ecosystem')
        
        # Skip variables we've already defined
        var_match = re.match(r'^([A-Z_]+)=', line)
        if var_match and var_match.group(1) in seen_vars:
            continue
            
        new_lines.append(line)
    
    # Write updated content
    with open(env_path, 'w') as f:
        f.writelines(new_lines)
    
    print(f"‚úì Updated {env_path}")

def add_security_warning():
    """Add security warnings to sensitive .env files."""
    sensitive_files = [
        f"{ECOSYSTEM_ROOT}/data_lake/.env",
    ]
    
    warning = """# ‚ö†Ô∏è  SECURITY WARNING ‚ö†Ô∏è
# This file contains sensitive credentials. 
# DO NOT commit this file to version control!
# Use .env.local for actual credentials and .env.template for examples.

"""
    
    for file_path in sensitive_files:
        if os.path.exists(file_path):
            with open(file_path, 'r') as f:
                content = f.read()
            
            if "SECURITY WARNING" not in content:
                with open(file_path, 'w') as f:
                    f.write(warning + content)
                print(f"‚úì Added security warning to {file_path}")

def main():
    """Main harmonization process."""
    print("üöÄ BEDROT Environment Harmonization Tool")
    print("=" * 50)
    
    # Define environment files and their components
    env_files = {
        f"{ECOSYSTEM_ROOT}/.env": "root",
        f"{ECOSYSTEM_ROOT}/data_lake/.env": "data_lake",
        f"{ECOSYSTEM_ROOT}/data-warehouse/.env": "data_warehouse",
        f"{ECOSYSTEM_ROOT}/data_dashboard/.env": "dashboard",
        f"{ECOSYSTEM_ROOT}/data_dashboard/backend/.env": "dashboard",
    }
    
    # Process each file
    for env_path, component in env_files.items():
        standardize_env_file(env_path, component)
    
    # Add security warnings
    add_security_warning()
    
    print("\n‚úÖ Environment harmonization complete!")
    print("\nüìã Next steps:")
    print("1. Review the updated .env files")
    print("2. Move sensitive credentials to .env.local files")
    print("3. Test the pipeline with harmonized configuration")

if __name__ == "__main__":
    main()